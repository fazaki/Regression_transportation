{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import * #to support struct type schema\n",
    "from functools import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Taxi\")\\\n",
    "        .config(\"spark.driver.memory\", \"25g\")\\\n",
    "        .config(\"spark.driver.cores\", \"4\")\\\n",
    "        .getOrCreate()\n",
    "sc=spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.rdd import portable_hash\n",
    "# from pyspark.statcounter import StatCounter\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "#from itertools import chain, imap\n",
    "from shapely.geometry import shape, Point\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to print RDD content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pprint import pprint\n",
    "def title(s):\n",
    "    pprint(\"---- %s -----\" %s)    \n",
    "    \n",
    "def see(s, v):\n",
    "    pprint(\"---- %s -----\" %s)\n",
    "    pprint(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiRaw_Rdd = sc.textFile(\"data/yellow_tripdata_2015-12.csv\")\n",
    "#header = sc.parallelize(taxiRawAll.take(1))\n",
    "#taxiRaw = taxiRaw.coalesce(1) #Makes 1 file as an output, since it reduced the # of partitions to 1\n",
    "#header.union(taxiRaw).coalesce(1).saveAsTextFile(\"../../data/ch08-geospatial/trip_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---- taxiRaw_Rdd -----'\n",
      "['VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,RatecodeID,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount',\n",
      " '2,2015-12-01 00:00:00,2015-12-01 '\n",
      " '00:05:16,5,.96,-73.979942321777344,40.765380859375,1,N,-73.96630859375,40.763088226318359,1,5.5,0.5,0.5,1,0,0.3,7.8']\n"
     ]
    }
   ],
   "source": [
    "see(\"taxiRaw_Rdd\",taxiRaw_Rdd.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11460574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiRaw_Rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parse the needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---- taxiParsed_rdd -----'\n",
      "[(datetime.datetime(2015, 12, 1, 0, 0),\n",
      "  -73.97994232177734,\n",
      "  40.765380859375,\n",
      "  -73.96630859375,\n",
      "  40.76308822631836,\n",
      "  5),\n",
      " (datetime.datetime(2015, 12, 1, 0, 0),\n",
      "  -73.97233581542969,\n",
      "  40.76237869262695,\n",
      "  -73.9936294555664,\n",
      "  40.74599838256836,\n",
      "  2)]\n"
     ]
    }
   ],
   "source": [
    "def parse(fields):\n",
    "    \n",
    "    pickupTime = datetime.strptime(fields[1], '%Y-%m-%d %H:%M:%S')\n",
    "    Count = int(fields[3])\n",
    "    PU_lat = float(fields[5]) \n",
    "    PU_lng = float(fields[6])\n",
    "    DO_lat = float(fields[9]) \n",
    "    DO_lng = float(fields[10])\n",
    "\n",
    "    return (pickupTime, PU_lat, PU_lng, DO_lat, DO_lng, Count)\n",
    "\n",
    "\n",
    "taxiParsed_rdd = taxiRaw_Rdd\\\n",
    "        .map(lambda line: line.split(','))\\\n",
    "        .filter(lambda fields: len(fields) == 19 and fields[0] != \"VendorID\")\\\n",
    "        .map(parse)\n",
    "taxiParsed_rdd.cache()\n",
    "\n",
    "see(\"taxiParsed_rdd\", taxiParsed_rdd.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11460573"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiParsed_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting the boundaries and eliminating the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 40.477399\n",
    "max_lat = 40.917577\n",
    "min_lng = -74.259090\n",
    "max_lng = -73.700272\n",
    "\n",
    "boundaries = {'min_lat':min_lat,'max_lat':max_lat,'min_lng':min_lng,'max_lng':max_lng}\n",
    "\n",
    "\n",
    "def boundary_limit(boundaries,row):\n",
    "    return (row[1] >= min_lng and row[1] <= max_lng)and\\\n",
    "            (row[2] >= min_lat and row[2] <= max_lat)and\\\n",
    "            (row[3] >= min_lng and row[3] <= max_lng)and\\\n",
    "            (row[4] >= min_lat and row[4] <= max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---- taxiReady_rdd -----'\n",
      "[(datetime.datetime(2015, 12, 1, 0, 0),\n",
      "  -73.97994232177734,\n",
      "  40.765380859375,\n",
      "  -73.96630859375,\n",
      "  40.76308822631836,\n",
      "  5),\n",
      " (datetime.datetime(2015, 12, 1, 0, 0),\n",
      "  -73.97233581542969,\n",
      "  40.76237869262695,\n",
      "  -73.9936294555664,\n",
      "  40.74599838256836,\n",
      "  2)]\n"
     ]
    }
   ],
   "source": [
    "taxiReady_rdd = taxiParsed_rdd.filter(lambda x:boundary_limit(boundaries,x))\n",
    "taxiReady_rdd.persist()\n",
    "taxiParsed_rdd.unpersist()\n",
    "see(\"taxiReady_rdd\", taxiReady_rdd.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11265525"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiReady_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiReady_df = taxiReady_rdd.toDF([\"datetime\",\"PU_lng\",\"PU_lat\",\"DO_lng\",\"DO_lat\",\"Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- PU_lng: double (nullable = true)\n",
      " |-- PU_lat: double (nullable = true)\n",
      " |-- DO_lng: double (nullable = true)\n",
      " |-- DO_lat: double (nullable = true)\n",
      " |-- Count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxiReady_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "|           datetime|            PU_lng|            PU_lat|            DO_lng|           DO_lat|Count|\n",
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "|2015-12-01 00:00:00|-73.97994232177734|   40.765380859375|   -73.96630859375|40.76308822631836|    5|\n",
      "|2015-12-01 00:00:00|-73.97233581542969| 40.76237869262695| -73.9936294555664|40.74599838256836|    2|\n",
      "|2015-12-01 00:00:00| -73.9688491821289|40.764530181884766|-73.97454833984375|40.79164123535156|    1|\n",
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxiReady_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save the clean file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiReady_df.coalesce(1).write.save(\"taxiReady_df.csv\",format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef toCSVLine(data):\\n    return ','.join(str(d) for d in data)\\ntaxiReady_rdd.map(toCSVLine).saveAsTextFile('taxiReady_df.csv')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving rdd to csv\n",
    "\"\"\"\n",
    "def toCSVLine(data):\n",
    "    return ','.join(str(d) for d in data)\n",
    "taxiReady_rdd.map(toCSVLine).saveAsTextFile('taxiReady_df.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load cleaned data (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "customSchema = StructType([ \\\n",
    "    StructField(\"_c0\", TimestampType(), True),\\\n",
    "    StructField(\"_c1\", FloatType(), True),\\\n",
    "    StructField(\"_c2\", FloatType(), True),\\\n",
    "    StructField(\"_c3\", FloatType(), True),\\\n",
    "    StructField(\"_c4\", FloatType(), True),\\\n",
    "    StructField(\"_c4\", LongType(), True)])\n",
    "\n",
    "taxiReady_df = spark.read.csv(\"taxiReady_df.csv\",inferSchema=True)\n",
    "taxiReady_df = taxiReady_df.withColumnRenamed('_c0', 'datetime')\\\n",
    "                           .withColumnRenamed('_c1', 'PU_lng')\\\n",
    "                           .withColumnRenamed('_c2', 'PU_lat')\\\n",
    "                           .withColumnRenamed('_c3', 'DO_lng')\\\n",
    "                           .withColumnRenamed('_c4', 'DO_lat')\\\n",
    "                           .withColumnRenamed('_c5', 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('datetime', 'timestamp'),\n",
       " ('PU_lng', 'double'),\n",
       " ('PU_lat', 'double'),\n",
       " ('DO_lng', 'double'),\n",
       " ('DO_lat', 'double'),\n",
       " ('Count', 'int')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiReady_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "|           datetime|            PU_lng|            PU_lat|            DO_lng|           DO_lat|Count|\n",
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "|2015-12-01 00:00:00|-73.97994232177734|   40.765380859375|   -73.96630859375|40.76308822631836|    5|\n",
      "|2015-12-01 00:00:00|-73.97233581542969| 40.76237869262695| -73.9936294555664|40.74599838256836|    2|\n",
      "|2015-12-01 00:00:00| -73.9688491821289|40.764530181884766|-73.97454833984375|40.79164123535156|    1|\n",
      "+-------------------+------------------+------------------+------------------+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxiReady_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the fishnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 40.477399\n",
    "max_lat = 40.917577\n",
    "min_lng = -74.259090\n",
    "max_lng = -73.700272\n",
    "\n",
    "boundaries = {'min_lat':min_lat,'max_lat':max_lat,'min_lng':min_lng,'max_lng':max_lng}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fishnet(df,boundaries = boundaries, lat_split = 20, lng_split = 30):\n",
    "    \"\"\"\n",
    "    boundaries: dictionary contains lat/lng min/max points\n",
    "    lat_split: number of lat splits\n",
    "    lng_split: number of lng splits\n",
    "    \"\"\"\n",
    "    lat_step = (boundaries['max_lat'] - boundaries['min_lat']) / lat_split\n",
    "    lng_step = (boundaries['max_lng'] - boundaries['min_lng']) / lng_split\n",
    "    min_lat = boundaries['min_lat']\n",
    "    min_lng = boundaries['min_lng']\n",
    "\n",
    "    #return (df-min_lat)//lat_split\n",
    "    return df.withColumn('Plat_grid', floor((df.PU_lat - min_lat)/lat_step))\\\n",
    "             .withColumn('Plng_grid', floor((df.PU_lng - min_lng)/lng_step))\\\n",
    "             .withColumn('Dlat_grid', floor((df.DO_lat - min_lat)/lat_step))\\\n",
    "             .withColumn('Dlng_grid', floor((df.DO_lng - min_lng)/lng_step))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+-----+---------+---------+---------+---------+\n",
      "|           datetime|            PU_lng|            PU_lat|            DO_lng|            DO_lat|Count|Plat_grid|Plng_grid|Dlat_grid|Dlng_grid|\n",
      "+-------------------+------------------+------------------+------------------+------------------+-----+---------+---------+---------+---------+\n",
      "|2015-12-01 00:00:00|-73.97994232177734|   40.765380859375|   -73.96630859375| 40.76308822631836|    5|       13|       14|       12|       15|\n",
      "|2015-12-01 00:00:00|-73.97233581542969| 40.76237869262695| -73.9936294555664| 40.74599838256836|    2|       12|       15|       12|       14|\n",
      "|2015-12-01 00:00:00| -73.9688491821289|40.764530181884766|-73.97454833984375| 40.79164123535156|    1|       13|       15|       14|       15|\n",
      "|2015-12-01 00:00:01|-73.99393463134766| 40.74168395996094|-73.99766540527344|40.747467041015625|    1|       12|       14|       12|       14|\n",
      "|2015-12-01 00:00:01|-73.98892211914062| 40.72698974609375|-73.97559356689453|40.696868896484375|    2|       11|       14|        9|       15|\n",
      "+-------------------+------------------+------------------+------------------+------------------+-----+---------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_grid_df = fishnet(taxiReady_df).cache()\n",
    "taxi_grid_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_grid_df.createOrReplaceTempView(\"taxi_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runQuery(sqlQuery):\n",
    "    \"\"\"\n",
    "    Receives:SQL Query as string\n",
    "    Returns first 10 rows of the result\n",
    "    \"\"\"\n",
    "    \n",
    "    spark.sql(sqlQuery).createOrReplaceTempView(\"out_table\")\n",
    "\n",
    "    title(\"Query first 10 Rows\")\n",
    "    spark.sql(\"SELECT * FROM out_table\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'---- Query first 10 Rows -----'\n",
      "+-------------------+---------+---------+---------+---------+\n",
      "|           datetime|Plat_grid|Plng_grid|Dlat_grid|Dlng_grid|\n",
      "+-------------------+---------+---------+---------+---------+\n",
      "|2015-12-06 11:55:34|       15|       17|       14|       15|\n",
      "|2015-12-06 11:57:16|       15|       17|       14|       15|\n",
      "|2015-12-06 12:05:12|       15|       17|       14|       16|\n",
      "|2015-12-06 12:08:33|       15|       17|       13|       14|\n",
      "|2015-12-06 12:11:27|       15|       17|        9|       18|\n",
      "|2015-12-06 12:15:08|       15|       17|       12|       15|\n",
      "|2015-12-06 12:17:38|       15|       17|       15|       16|\n",
      "|2015-12-06 12:20:40|       15|       17|       10|       13|\n",
      "|2015-12-06 12:25:39|       15|       17|       14|       17|\n",
      "|2015-12-06 12:26:16|       15|       17|       15|       16|\n",
      "+-------------------+---------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runQuery(\"SELECT datetime, Plat_grid, Plng_grid, Dlat_grid, Dlng_grid FROM taxi_all\\\n",
    "         WHERE datetime BETWEEN '2015-12-06 11:55:00' AND '2015-12-06 12:30:00'\\\n",
    "         AND Plat_grid = 15\\\n",
    "         AND Plng_grid = 17\\\n",
    "         ORDER BY datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
